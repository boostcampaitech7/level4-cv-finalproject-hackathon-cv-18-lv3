0	module.speech_query_tokens	139840443582400
1	module.llama_model.base_model.model.model.embed_tokens.weight	139833472441216
2	module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.weight	139833472441616
3	module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight	139833218509376
4	module.llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight	139833218508096
5	module.llama_model.base_model.model.model.layers.0.self_attn.k_proj.weight	139833472441936
6	module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.weight	139833472459216
7	module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight	139833218509696
8	module.llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight	139833218507776
9	module.llama_model.base_model.model.model.layers.0.self_attn.o_proj.weight	139833472459776
10	module.llama_model.base_model.model.model.layers.0.mlp.gate_proj.weight	139835711350320
11	module.llama_model.base_model.model.model.layers.0.mlp.up_proj.weight	139833472460416
12	module.llama_model.base_model.model.model.layers.0.mlp.down_proj.weight	139833472460016
13	module.llama_model.base_model.model.model.layers.0.input_layernorm.weight	139833472052736
14	module.llama_model.base_model.model.model.layers.0.post_attention_layernorm.weight	139833472052656
15	module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.weight	139833472317456
16	module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight	139833218509776
17	module.llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight	139833218506976
18	module.llama_model.base_model.model.model.layers.1.self_attn.k_proj.weight	139840778671264
19	module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.weight	139833472052496
20	module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight	139833218507376
21	module.llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight	139833218508736
22	module.llama_model.base_model.model.model.layers.1.self_attn.o_proj.weight	139833472053056
23	module.llama_model.base_model.model.model.layers.1.mlp.gate_proj.weight	139833472081568
24	module.llama_model.base_model.model.model.layers.1.mlp.up_proj.weight	139833472081808
25	module.llama_model.base_model.model.model.layers.1.mlp.down_proj.weight	139833472081488
26	module.llama_model.base_model.model.model.layers.1.input_layernorm.weight	139833472081648
27	module.llama_model.base_model.model.model.layers.1.post_attention_layernorm.weight	139833472092656
28	module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.weight	139833472091776
29	module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight	139833218961216
30	module.llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight	139833218509216
31	module.llama_model.base_model.model.model.layers.2.self_attn.k_proj.weight	139833472092816
32	module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.weight	139833472092896
33	module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight	139833218510256
34	module.llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight	139833218509856
35	module.llama_model.base_model.model.model.layers.2.self_attn.o_proj.weight	139833472092976
36	module.llama_model.base_model.model.model.layers.2.mlp.gate_proj.weight	139833472093456
37	module.llama_model.base_model.model.model.layers.2.mlp.up_proj.weight	139833472093216
38	module.llama_model.base_model.model.model.layers.2.mlp.down_proj.weight	139833472093056
39	module.llama_model.base_model.model.model.layers.2.input_layernorm.weight	139833472093136
40	module.llama_model.base_model.model.model.layers.2.post_attention_layernorm.weight	139833472093296
41	module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.weight	139833472093376
42	module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight	139833218509536
43	module.llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight	139833218506896
44	module.llama_model.base_model.model.model.layers.3.self_attn.k_proj.weight	139833472093616
45	module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.weight	139833472093696
46	module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight	139833218509616
47	module.llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight	139833218508656
48	module.llama_model.base_model.model.model.layers.3.self_attn.o_proj.weight	139833472093776
49	module.llama_model.base_model.model.model.layers.3.mlp.gate_proj.weight	139833472091856
50	module.llama_model.base_model.model.model.layers.3.mlp.up_proj.weight	139833472094016
51	module.llama_model.base_model.model.model.layers.3.mlp.down_proj.weight	139833472093856
52	module.llama_model.base_model.model.model.layers.3.input_layernorm.weight	139833472093936
53	module.llama_model.base_model.model.model.layers.3.post_attention_layernorm.weight	139833472094096
54	module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.weight	139833472092096
55	module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight	139833218507136
56	module.llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight	139833218510016
57	module.llama_model.base_model.model.model.layers.4.self_attn.k_proj.weight	139833472028736
58	module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.weight	139833472028816
59	module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight	139833218510336
60	module.llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight	139833218507296
61	module.llama_model.base_model.model.model.layers.4.self_attn.o_proj.weight	139833472028896
62	module.llama_model.base_model.model.model.layers.4.mlp.gate_proj.weight	139833472029376
63	module.llama_model.base_model.model.model.layers.4.mlp.up_proj.weight	139833472029136
64	module.llama_model.base_model.model.model.layers.4.mlp.down_proj.weight	139833472028976
65	module.llama_model.base_model.model.model.layers.4.input_layernorm.weight	139833472029056
66	module.llama_model.base_model.model.model.layers.4.post_attention_layernorm.weight	139833472029216
67	module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.weight	139833472029296
68	module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight	139833218507696
69	module.llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight	139833218508416
70	module.llama_model.base_model.model.model.layers.5.self_attn.k_proj.weight	139833472029536
71	module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.weight	139833472029616
72	module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight	139833218508496
73	module.llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight	139833218508896
74	module.llama_model.base_model.model.model.layers.5.self_attn.o_proj.weight	139833472029696
75	module.llama_model.base_model.model.model.layers.5.mlp.gate_proj.weight	139833472030176
76	module.llama_model.base_model.model.model.layers.5.mlp.up_proj.weight	139833472029936
77	module.llama_model.base_model.model.model.layers.5.mlp.down_proj.weight	139833472029776
78	module.llama_model.base_model.model.model.layers.5.input_layernorm.weight	139833472029856
79	module.llama_model.base_model.model.model.layers.5.post_attention_layernorm.weight	139833472030016
80	module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.weight	139833472030096
81	module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight	139833218507616
82	module.llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight	139833218508176
83	module.llama_model.base_model.model.model.layers.6.self_attn.k_proj.weight	139833472030336
84	module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.weight	139833472030416
85	module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight	139833218507936
86	module.llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight	139833218508576
87	module.llama_model.base_model.model.model.layers.6.self_attn.o_proj.weight	139833472030496
88	module.llama_model.base_model.model.model.layers.6.mlp.gate_proj.weight	139833472030976
89	module.llama_model.base_model.model.model.layers.6.mlp.up_proj.weight	139833472030736
90	module.llama_model.base_model.model.model.layers.6.mlp.down_proj.weight	139833472030576
91	module.llama_model.base_model.model.model.layers.6.input_layernorm.weight	139833472030656
92	module.llama_model.base_model.model.model.layers.6.post_attention_layernorm.weight	139833472030816
93	module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.weight	139833472030896
94	module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight	139833218510416
95	module.llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight	139833218508976
96	module.llama_model.base_model.model.model.layers.7.self_attn.k_proj.weight	139833472031136
97	module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.weight	139833472031216
98	module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight	139833218509056
99	module.llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight	139833218507216
100	module.llama_model.base_model.model.model.layers.7.self_attn.o_proj.weight	139833472031296
101	module.llama_model.base_model.model.model.layers.7.mlp.gate_proj.weight	139833472031776
102	module.llama_model.base_model.model.model.layers.7.mlp.up_proj.weight	139833472031536
103	module.llama_model.base_model.model.model.layers.7.mlp.down_proj.weight	139833472031376
104	module.llama_model.base_model.model.model.layers.7.input_layernorm.weight	139833472031456
105	module.llama_model.base_model.model.model.layers.7.post_attention_layernorm.weight	139833472031616
106	module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.weight	139833472031696
107	module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight	139833218507056
108	module.llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight	139833218508256
109	module.llama_model.base_model.model.model.layers.8.self_attn.k_proj.weight	139833472031936
110	module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.weight	139833472032016
111	module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight	139833218507536
112	module.llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight	139833218510736
113	module.llama_model.base_model.model.model.layers.8.self_attn.o_proj.weight	139833472032096
114	module.llama_model.base_model.model.model.layers.8.mlp.gate_proj.weight	139833472032576
115	module.llama_model.base_model.model.model.layers.8.mlp.up_proj.weight	139833472032336
116	module.llama_model.base_model.model.model.layers.8.mlp.down_proj.weight	139833472032176
117	module.llama_model.base_model.model.model.layers.8.input_layernorm.weight	139833472032256
118	module.llama_model.base_model.model.model.layers.8.post_attention_layernorm.weight	139833472032416
119	module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.weight	139833472032496
120	module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight	139833218509296
121	module.llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight	139833218509136
122	module.llama_model.base_model.model.model.layers.9.self_attn.k_proj.weight	139833219608640
123	module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.weight	139833219608720
124	module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight	139833218508816
125	module.llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight	139833218507456
126	module.llama_model.base_model.model.model.layers.9.self_attn.o_proj.weight	139833219608800
127	module.llama_model.base_model.model.model.layers.9.mlp.gate_proj.weight	139833219609280
128	module.llama_model.base_model.model.model.layers.9.mlp.up_proj.weight	139833219609040
129	module.llama_model.base_model.model.model.layers.9.mlp.down_proj.weight	139833219608880
130	module.llama_model.base_model.model.model.layers.9.input_layernorm.weight	139833219608960
131	module.llama_model.base_model.model.model.layers.9.post_attention_layernorm.weight	139833219609120
132	module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.weight	139833219609200
133	module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight	139833218960976
134	module.llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight	139835713646896
135	module.llama_model.base_model.model.model.layers.10.self_attn.k_proj.weight	139833219609440
136	module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.weight	139833219609520
137	module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight	139833218041072
138	module.llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight	139833218040832
139	module.llama_model.base_model.model.model.layers.10.self_attn.o_proj.weight	139833219609600
140	module.llama_model.base_model.model.model.layers.10.mlp.gate_proj.weight	139833219610080
141	module.llama_model.base_model.model.model.layers.10.mlp.up_proj.weight	139833219609840
142	module.llama_model.base_model.model.model.layers.10.mlp.down_proj.weight	139833219609680
143	module.llama_model.base_model.model.model.layers.10.input_layernorm.weight	139833219609760
144	module.llama_model.base_model.model.model.layers.10.post_attention_layernorm.weight	139833219609920
145	module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.weight	139833219610000
146	module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight	139833218042192
147	module.llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight	139833218040912
148	module.llama_model.base_model.model.model.layers.11.self_attn.k_proj.weight	139833219610240
149	module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.weight	139833219610320
150	module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight	139833218041552
151	module.llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight	139833218041872
152	module.llama_model.base_model.model.model.layers.11.self_attn.o_proj.weight	139833219610400
153	module.llama_model.base_model.model.model.layers.11.mlp.gate_proj.weight	139833219610880
154	module.llama_model.base_model.model.model.layers.11.mlp.up_proj.weight	139833219610640
155	module.llama_model.base_model.model.model.layers.11.mlp.down_proj.weight	139833219610480
156	module.llama_model.base_model.model.model.layers.11.input_layernorm.weight	139833219610560
157	module.llama_model.base_model.model.model.layers.11.post_attention_layernorm.weight	139833219610720
158	module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.weight	139833219610800
159	module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight	139833218042032
160	module.llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight	139833218041152
161	module.llama_model.base_model.model.model.layers.12.self_attn.k_proj.weight	139833219611040
162	module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.weight	139833219611120
163	module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight	139833218042352
164	module.llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight	139833218040032
165	module.llama_model.base_model.model.model.layers.12.self_attn.o_proj.weight	139833219611200
166	module.llama_model.base_model.model.model.layers.12.mlp.gate_proj.weight	139833219611680
167	module.llama_model.base_model.model.model.layers.12.mlp.up_proj.weight	139833219611440
168	module.llama_model.base_model.model.model.layers.12.mlp.down_proj.weight	139833219611280
169	module.llama_model.base_model.model.model.layers.12.input_layernorm.weight	139833219611360
170	module.llama_model.base_model.model.model.layers.12.post_attention_layernorm.weight	139833219611520
171	module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.weight	139833219611600
172	module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight	139833218042432
173	module.llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight	139833218041312
174	module.llama_model.base_model.model.model.layers.13.self_attn.k_proj.weight	139833219611840
175	module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.weight	139833219611920
176	module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight	139833218039872
177	module.llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight	139833218040672
178	module.llama_model.base_model.model.model.layers.13.self_attn.o_proj.weight	139833219612000
179	module.llama_model.base_model.model.model.layers.13.mlp.gate_proj.weight	139833219612480
180	module.llama_model.base_model.model.model.layers.13.mlp.up_proj.weight	139833219612240
181	module.llama_model.base_model.model.model.layers.13.mlp.down_proj.weight	139833219612080
182	module.llama_model.base_model.model.model.layers.13.input_layernorm.weight	139833219612160
183	module.llama_model.base_model.model.model.layers.13.post_attention_layernorm.weight	139833219612320
184	module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.weight	139833219612400
185	module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight	139833218042512
186	module.llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight	139833218040112
187	module.llama_model.base_model.model.model.layers.14.self_attn.k_proj.weight	139833219391552
188	module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.weight	139833219391632
189	module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight	139833218041232
190	module.llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight	139833218040512
191	module.llama_model.base_model.model.model.layers.14.self_attn.o_proj.weight	139833219391712
192	module.llama_model.base_model.model.model.layers.14.mlp.gate_proj.weight	139833219392192
193	module.llama_model.base_model.model.model.layers.14.mlp.up_proj.weight	139833219391952
194	module.llama_model.base_model.model.model.layers.14.mlp.down_proj.weight	139833219391792
195	module.llama_model.base_model.model.model.layers.14.input_layernorm.weight	139833219391872
196	module.llama_model.base_model.model.model.layers.14.post_attention_layernorm.weight	139833219392032
197	module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.weight	139833219392112
198	module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight	139833218042112
199	module.llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight	139833218040752
200	module.llama_model.base_model.model.model.layers.15.self_attn.k_proj.weight	139833219392352
201	module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.weight	139833219392432
202	module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight	139833218041632
203	module.llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight	139833218040272
204	module.llama_model.base_model.model.model.layers.15.self_attn.o_proj.weight	139833219392512
205	module.llama_model.base_model.model.model.layers.15.mlp.gate_proj.weight	139833219392992
206	module.llama_model.base_model.model.model.layers.15.mlp.up_proj.weight	139833219392752
207	module.llama_model.base_model.model.model.layers.15.mlp.down_proj.weight	139833219392592
208	module.llama_model.base_model.model.model.layers.15.input_layernorm.weight	139833219392672
209	module.llama_model.base_model.model.model.layers.15.post_attention_layernorm.weight	139833219392832
210	module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.weight	139833219392912
211	module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight	139833218040432
212	module.llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight	139833218041712
213	module.llama_model.base_model.model.model.layers.16.self_attn.k_proj.weight	139833219393152
214	module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.weight	139833219393232
215	module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight	139833218040992
216	module.llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight	139833218041792
217	module.llama_model.base_model.model.model.layers.16.self_attn.o_proj.weight	139833219393312
218	module.llama_model.base_model.model.model.layers.16.mlp.gate_proj.weight	139833219393792
219	module.llama_model.base_model.model.model.layers.16.mlp.up_proj.weight	139833219393552
220	module.llama_model.base_model.model.model.layers.16.mlp.down_proj.weight	139833219393392
221	module.llama_model.base_model.model.model.layers.16.input_layernorm.weight	139833219393472
222	module.llama_model.base_model.model.model.layers.16.post_attention_layernorm.weight	139833219393632
223	module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.weight	139833219393712
224	module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight	139833218040192
225	module.llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight	139833218040352
226	module.llama_model.base_model.model.model.layers.17.self_attn.k_proj.weight	139833219393952
227	module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.weight	139833219394032
228	module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight	139833218041392
229	module.llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight	139833218039952
230	module.llama_model.base_model.model.model.layers.17.self_attn.o_proj.weight	139833219394112
231	module.llama_model.base_model.model.model.layers.17.mlp.gate_proj.weight	139833219394592
232	module.llama_model.base_model.model.model.layers.17.mlp.up_proj.weight	139833219394352
233	module.llama_model.base_model.model.model.layers.17.mlp.down_proj.weight	139833219394192
234	module.llama_model.base_model.model.model.layers.17.input_layernorm.weight	139833219394272
235	module.llama_model.base_model.model.model.layers.17.post_attention_layernorm.weight	139833219394432
236	module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.weight	139833219394512
237	module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight	139833218041472
238	module.llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight	139833218042272
239	module.llama_model.base_model.model.model.layers.18.self_attn.k_proj.weight	139833219394752
240	module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.weight	139833219394832
241	module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight	139833473056016
242	module.llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight	139833472532288
243	module.llama_model.base_model.model.model.layers.18.self_attn.o_proj.weight	139833219394912
244	module.llama_model.base_model.model.model.layers.18.mlp.gate_proj.weight	139833219395392
245	module.llama_model.base_model.model.model.layers.18.mlp.up_proj.weight	139833219395152
246	module.llama_model.base_model.model.model.layers.18.mlp.down_proj.weight	139833219394992
247	module.llama_model.base_model.model.model.layers.18.input_layernorm.weight	139833219395072
248	module.llama_model.base_model.model.model.layers.18.post_attention_layernorm.weight	139833219395232
249	module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.weight	139833219395312
250	module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight	139833218124832
251	module.llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight	139833218125232
252	module.llama_model.base_model.model.model.layers.19.self_attn.k_proj.weight	139833219174464
253	module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.weight	139833219174544
254	module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight	139833218124752
255	module.llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight	139833218125632
256	module.llama_model.base_model.model.model.layers.19.self_attn.o_proj.weight	139833219174624
257	module.llama_model.base_model.model.model.layers.19.mlp.gate_proj.weight	139833219175104
258	module.llama_model.base_model.model.model.layers.19.mlp.up_proj.weight	139833219174864
259	module.llama_model.base_model.model.model.layers.19.mlp.down_proj.weight	139833219174704
260	module.llama_model.base_model.model.model.layers.19.input_layernorm.weight	139833219174784
261	module.llama_model.base_model.model.model.layers.19.post_attention_layernorm.weight	139833219174944
262	module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.weight	139833219175024
263	module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight	139833218124912
264	module.llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight	139833218125072
265	module.llama_model.base_model.model.model.layers.20.self_attn.k_proj.weight	139833219175264
266	module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.weight	139833219175344
267	module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight	139833218125312
268	module.llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight	139833218125392
269	module.llama_model.base_model.model.model.layers.20.self_attn.o_proj.weight	139833219175424
270	module.llama_model.base_model.model.model.layers.20.mlp.gate_proj.weight	139833219175904
271	module.llama_model.base_model.model.model.layers.20.mlp.up_proj.weight	139833219175664
272	module.llama_model.base_model.model.model.layers.20.mlp.down_proj.weight	139833219175504
273	module.llama_model.base_model.model.model.layers.20.input_layernorm.weight	139833219175584
274	module.llama_model.base_model.model.model.layers.20.post_attention_layernorm.weight	139833219175744
275	module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.weight	139833219175824
276	module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight	139833218125552
277	module.llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight	139833218125472
278	module.llama_model.base_model.model.model.layers.21.self_attn.k_proj.weight	139833219176064
279	module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.weight	139833219176144
280	module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight	139833218040592
281	module.llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight	139833217146944
282	module.llama_model.base_model.model.model.layers.21.self_attn.o_proj.weight	139833219176224
283	module.llama_model.base_model.model.model.layers.21.mlp.gate_proj.weight	139833219176704
284	module.llama_model.base_model.model.model.layers.21.mlp.up_proj.weight	139833219176464
285	module.llama_model.base_model.model.model.layers.21.mlp.down_proj.weight	139833219176304
286	module.llama_model.base_model.model.model.layers.21.input_layernorm.weight	139833219176384
287	module.llama_model.base_model.model.model.layers.21.post_attention_layernorm.weight	139833219176544
288	module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.weight	139833219176624
289	module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight	139833217147024
290	module.llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight	139833217147104
291	module.llama_model.base_model.model.model.layers.22.self_attn.k_proj.weight	139833219176864
292	module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.weight	139833219176944
293	module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight	139833217147184
294	module.llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight	139833217147264
295	module.llama_model.base_model.model.model.layers.22.self_attn.o_proj.weight	139833219177024
296	module.llama_model.base_model.model.model.layers.22.mlp.gate_proj.weight	139833219177504
297	module.llama_model.base_model.model.model.layers.22.mlp.up_proj.weight	139833219177264
298	module.llama_model.base_model.model.model.layers.22.mlp.down_proj.weight	139833219177104
299	module.llama_model.base_model.model.model.layers.22.input_layernorm.weight	139833219177184
300	module.llama_model.base_model.model.model.layers.22.post_attention_layernorm.weight	139833219177344
301	module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.weight	139833219177424
302	module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight	139833217147344
303	module.llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight	139833217147424
304	module.llama_model.base_model.model.model.layers.23.self_attn.k_proj.weight	139833219177664
305	module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.weight	139833219177744
306	module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight	139833217147504
307	module.llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight	139833217147584
308	module.llama_model.base_model.model.model.layers.23.self_attn.o_proj.weight	139833219177824
309	module.llama_model.base_model.model.model.layers.23.mlp.gate_proj.weight	139833219178304
310	module.llama_model.base_model.model.model.layers.23.mlp.up_proj.weight	139833219178064
311	module.llama_model.base_model.model.model.layers.23.mlp.down_proj.weight	139833219177904
312	module.llama_model.base_model.model.model.layers.23.input_layernorm.weight	139833219177984
313	module.llama_model.base_model.model.model.layers.23.post_attention_layernorm.weight	139833219178144
314	module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.weight	139833219178224
315	module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight	139833217147664
316	module.llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight	139833217147744
317	module.llama_model.base_model.model.model.layers.24.self_attn.k_proj.weight	139833218957376
318	module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.weight	139833218957456
319	module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight	139833217147824
320	module.llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight	139833217147904
321	module.llama_model.base_model.model.model.layers.24.self_attn.o_proj.weight	139833218957536
322	module.llama_model.base_model.model.model.layers.24.mlp.gate_proj.weight	139833218958016
323	module.llama_model.base_model.model.model.layers.24.mlp.up_proj.weight	139833218957776
324	module.llama_model.base_model.model.model.layers.24.mlp.down_proj.weight	139833218957616
325	module.llama_model.base_model.model.model.layers.24.input_layernorm.weight	139833218957696
326	module.llama_model.base_model.model.model.layers.24.post_attention_layernorm.weight	139833218957856
327	module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.weight	139833218957936
328	module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight	139833217147984
329	module.llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight	139833217148064
330	module.llama_model.base_model.model.model.layers.25.self_attn.k_proj.weight	139833218958176
331	module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.weight	139833218958256
332	module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight	139833217148144
333	module.llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight	139833217148224
334	module.llama_model.base_model.model.model.layers.25.self_attn.o_proj.weight	139833218958336
335	module.llama_model.base_model.model.model.layers.25.mlp.gate_proj.weight	139833218958816
336	module.llama_model.base_model.model.model.layers.25.mlp.up_proj.weight	139833218958576
337	module.llama_model.base_model.model.model.layers.25.mlp.down_proj.weight	139833218958416
338	module.llama_model.base_model.model.model.layers.25.input_layernorm.weight	139833218958496
339	module.llama_model.base_model.model.model.layers.25.post_attention_layernorm.weight	139833218958656
340	module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.weight	139833218958736
341	module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight	139833217148304
342	module.llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight	139833217148384
343	module.llama_model.base_model.model.model.layers.26.self_attn.k_proj.weight	139833218958976
344	module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.weight	139833218959056
345	module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight	139833217148464
346	module.llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight	139833217148544
347	module.llama_model.base_model.model.model.layers.26.self_attn.o_proj.weight	139833218959136
348	module.llama_model.base_model.model.model.layers.26.mlp.gate_proj.weight	139833218959616
349	module.llama_model.base_model.model.model.layers.26.mlp.up_proj.weight	139833218959376
350	module.llama_model.base_model.model.model.layers.26.mlp.down_proj.weight	139833218959216
351	module.llama_model.base_model.model.model.layers.26.input_layernorm.weight	139833218959296
352	module.llama_model.base_model.model.model.layers.26.post_attention_layernorm.weight	139833218959456
353	module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.weight	139833218959536
354	module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight	139833217148624
355	module.llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight	139833217148704
356	module.llama_model.base_model.model.model.layers.27.self_attn.k_proj.weight	139833218959776
357	module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.weight	139833218959856
358	module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight	139833217148784
359	module.llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight	139833217148864
360	module.llama_model.base_model.model.model.layers.27.self_attn.o_proj.weight	139833218959936
361	module.llama_model.base_model.model.model.layers.27.mlp.gate_proj.weight	139833218960416
362	module.llama_model.base_model.model.model.layers.27.mlp.up_proj.weight	139833218960176
363	module.llama_model.base_model.model.model.layers.27.mlp.down_proj.weight	139833218960016
364	module.llama_model.base_model.model.model.layers.27.input_layernorm.weight	139833218960096
365	module.llama_model.base_model.model.model.layers.27.post_attention_layernorm.weight	139833218960256
366	module.llama_model.base_model.model.model.norm.weight	139833218960336
367	module.speech_encoder.conv1.weight	139832496750656
368	module.speech_encoder.conv1.bias	139832496752976
369	module.speech_encoder.conv2.weight	139832496750736
370	module.speech_encoder.conv2.bias	139832496754256
371	module.speech_encoder.embed_positions.weight	139837172281568
372	module.speech_encoder.layers.0.self_attn.k_proj.weight	139832496751536
373	module.speech_encoder.layers.0.self_attn.v_proj.weight	139832496753056
374	module.speech_encoder.layers.0.self_attn.v_proj.bias	139832496753856
375	module.speech_encoder.layers.0.self_attn.q_proj.weight	139837172240192
376	module.speech_encoder.layers.0.self_attn.q_proj.bias	139837172240112
377	module.speech_encoder.layers.0.self_attn.out_proj.weight	139837172240032
378	module.speech_encoder.layers.0.self_attn.out_proj.bias	139837172239952
379	module.speech_encoder.layers.0.self_attn_layer_norm.weight	139837172239632
380	module.speech_encoder.layers.0.self_attn_layer_norm.bias	139837172239712
381	module.speech_encoder.layers.0.fc1.weight	139837172239872
382	module.speech_encoder.layers.0.fc1.bias	139832496752816
383	module.speech_encoder.layers.0.fc2.weight	139837172239792
384	module.speech_encoder.layers.0.fc2.bias	139832496753616
385	module.speech_encoder.layers.0.final_layer_norm.weight	139837172239232
386	module.speech_encoder.layers.0.final_layer_norm.bias	139837172239312
387	module.speech_encoder.layers.1.self_attn.k_proj.weight	139837172239392
388	module.speech_encoder.layers.1.self_attn.v_proj.weight	139837172239552
389	module.speech_encoder.layers.1.self_attn.v_proj.bias	139837172239152
390	module.speech_encoder.layers.1.self_attn.q_proj.weight	139837172238832
391	module.speech_encoder.layers.1.self_attn.q_proj.bias	139837172238752
392	module.speech_encoder.layers.1.self_attn.out_proj.weight	139837172238672
393	module.speech_encoder.layers.1.self_attn.out_proj.bias	139837172238592
394	module.speech_encoder.layers.1.self_attn_layer_norm.weight	139837172238352
395	module.speech_encoder.layers.1.self_attn_layer_norm.bias	139837172238432
396	module.speech_encoder.layers.1.fc1.weight	139837172238512
397	module.speech_encoder.layers.1.fc1.bias	139837172239472
398	module.speech_encoder.layers.1.fc2.weight	139837172238272
399	module.speech_encoder.layers.1.fc2.bias	139837172238912
400	module.speech_encoder.layers.1.final_layer_norm.weight	139837172238992
401	module.speech_encoder.layers.1.final_layer_norm.bias	139837172239072
402	module.speech_encoder.layers.2.self_attn.k_proj.weight	139837172238032
403	module.speech_encoder.layers.2.self_attn.v_proj.weight	139837172230640
404	module.speech_encoder.layers.2.self_attn.v_proj.bias	139837172238192
405	module.speech_encoder.layers.2.self_attn.q_proj.weight	139837172230480
406	module.speech_encoder.layers.2.self_attn.q_proj.bias	139837172230400
407	module.speech_encoder.layers.2.self_attn.out_proj.weight	139837172230320
408	module.speech_encoder.layers.2.self_attn.out_proj.bias	139837172230240
409	module.speech_encoder.layers.2.self_attn_layer_norm.weight	139837172230000
410	module.speech_encoder.layers.2.self_attn_layer_norm.bias	139837172230080
411	module.speech_encoder.layers.2.fc1.weight	139837172230160
412	module.speech_encoder.layers.2.fc1.bias	139837172238112
413	module.speech_encoder.layers.2.fc2.weight	139837172229920
414	module.speech_encoder.layers.2.fc2.bias	139837172230560
415	module.speech_encoder.layers.2.final_layer_norm.weight	139837172229520
416	module.speech_encoder.layers.2.final_layer_norm.bias	139837172229600
417	module.speech_encoder.layers.3.self_attn.k_proj.weight	139837172229680
418	module.speech_encoder.layers.3.self_attn.v_proj.weight	139837172229840
419	module.speech_encoder.layers.3.self_attn.v_proj.bias	139837172229440
420	module.speech_encoder.layers.3.self_attn.q_proj.weight	139837172229280
421	module.speech_encoder.layers.3.self_attn.q_proj.bias	139837172228960
422	module.speech_encoder.layers.3.self_attn.out_proj.weight	139837172228880
423	module.speech_encoder.layers.3.self_attn.out_proj.bias	139837172228800
424	module.speech_encoder.layers.3.self_attn_layer_norm.weight	139837172229040
425	module.speech_encoder.layers.3.self_attn_layer_norm.bias	139837172229120
426	module.speech_encoder.layers.3.fc1.weight	139837172229200
427	module.speech_encoder.layers.3.fc1.bias	139837172229760
428	module.speech_encoder.layers.3.fc2.weight	139837172228720
429	module.speech_encoder.layers.3.fc2.bias	139837172229360
430	module.speech_encoder.layers.3.final_layer_norm.weight	139837172228320
431	module.speech_encoder.layers.3.final_layer_norm.bias	139837172228400
432	module.speech_encoder.layers.4.self_attn.k_proj.weight	139837172228480
433	module.speech_encoder.layers.4.self_attn.v_proj.weight	139837172228640
434	module.speech_encoder.layers.4.self_attn.v_proj.bias	139837172228240
435	module.speech_encoder.layers.4.self_attn.q_proj.weight	139837172230880
436	module.speech_encoder.layers.4.self_attn.q_proj.bias	139837172230800
437	module.speech_encoder.layers.4.self_attn.out_proj.weight	139837172270320
438	module.speech_encoder.layers.4.self_attn.out_proj.bias	139837172230720
439	module.speech_encoder.layers.4.self_attn_layer_norm.weight	139837172270160
440	module.speech_encoder.layers.4.self_attn_layer_norm.bias	139837172270240
441	module.speech_encoder.layers.4.fc1.weight	139837172270080
442	module.speech_encoder.layers.4.fc1.bias	139837172228560
443	module.speech_encoder.layers.4.fc2.weight	139837172270000
444	module.speech_encoder.layers.4.fc2.bias	139837172228160
445	module.speech_encoder.layers.4.final_layer_norm.weight	139837172269600
446	module.speech_encoder.layers.4.final_layer_norm.bias	139837172269680
447	module.speech_encoder.layers.5.self_attn.k_proj.weight	139837172269760
448	module.speech_encoder.layers.5.self_attn.v_proj.weight	139837172269920
449	module.speech_encoder.layers.5.self_attn.v_proj.bias	139837172269520
450	module.speech_encoder.layers.5.self_attn.q_proj.weight	139837172269360
451	module.speech_encoder.layers.5.self_attn.q_proj.bias	139837172269280
452	module.speech_encoder.layers.5.self_attn.out_proj.weight	139837172269200
453	module.speech_encoder.layers.5.self_attn.out_proj.bias	139837172269120
454	module.speech_encoder.layers.5.self_attn_layer_norm.weight	139837172272720
455	module.speech_encoder.layers.5.self_attn_layer_norm.bias	139837172272800
456	module.speech_encoder.layers.5.fc1.weight	139837172272880
457	module.speech_encoder.layers.5.fc1.bias	139837172269840
458	module.speech_encoder.layers.5.fc2.weight	139837172272640
459	module.speech_encoder.layers.5.fc2.bias	139837172269440
460	module.speech_encoder.layers.5.final_layer_norm.weight	139837172272240
461	module.speech_encoder.layers.5.final_layer_norm.bias	139837172272320
462	module.speech_encoder.layers.6.self_attn.k_proj.weight	139837172272400
463	module.speech_encoder.layers.6.self_attn.v_proj.weight	139837172272560
464	module.speech_encoder.layers.6.self_attn.v_proj.bias	139837172272160
465	module.speech_encoder.layers.6.self_attn.q_proj.weight	139837172272000
466	module.speech_encoder.layers.6.self_attn.q_proj.bias	139837172273040
467	module.speech_encoder.layers.6.self_attn.out_proj.weight	139837172272960
468	module.speech_encoder.layers.6.self_attn.out_proj.bias	139837172270480
469	module.speech_encoder.layers.6.self_attn_layer_norm.weight	139837172267904
470	module.speech_encoder.layers.6.self_attn_layer_norm.bias	139837172272080
471	module.speech_encoder.layers.6.fc1.weight	139837172267824
472	module.speech_encoder.layers.6.fc1.bias	139837172272480
473	module.speech_encoder.layers.6.fc2.weight	139837172267744
474	module.speech_encoder.layers.6.fc2.bias	139837172270400
475	module.speech_encoder.layers.6.final_layer_norm.weight	139837172267344
476	module.speech_encoder.layers.6.final_layer_norm.bias	139837172267424
477	module.speech_encoder.layers.7.self_attn.k_proj.weight	139837172267504
478	module.speech_encoder.layers.7.self_attn.v_proj.weight	139837172267664
479	module.speech_encoder.layers.7.self_attn.v_proj.bias	139837172267264
480	module.speech_encoder.layers.7.self_attn.q_proj.weight	139837172267104
481	module.speech_encoder.layers.7.self_attn.q_proj.bias	139837172267024
482	module.speech_encoder.layers.7.self_attn.out_proj.weight	139837172266784
483	module.speech_encoder.layers.7.self_attn.out_proj.bias	139837172266704
484	module.speech_encoder.layers.7.self_attn_layer_norm.weight	139837172266624
485	module.speech_encoder.layers.7.self_attn_layer_norm.bias	139837172266864
486	module.speech_encoder.layers.7.fc1.weight	139837172266944
487	module.speech_encoder.layers.7.fc1.bias	139837172267584
488	module.speech_encoder.layers.7.fc2.weight	139837172266544
489	module.speech_encoder.layers.7.fc2.bias	139837172267184
490	module.speech_encoder.layers.7.final_layer_norm.weight	139837172266144
491	module.speech_encoder.layers.7.final_layer_norm.bias	139837172266224
492	module.speech_encoder.layers.8.self_attn.k_proj.weight	139837172266304
493	module.speech_encoder.layers.8.self_attn.v_proj.weight	139837172266464
494	module.speech_encoder.layers.8.self_attn.v_proj.bias	139837172266064
495	module.speech_encoder.layers.8.self_attn.q_proj.weight	139837172265904
496	module.speech_encoder.layers.8.self_attn.q_proj.bias	139837172265824
497	module.speech_encoder.layers.8.self_attn.out_proj.weight	139837172265744
498	module.speech_encoder.layers.8.self_attn.out_proj.bias	139837172265664
499	module.speech_encoder.layers.8.self_attn_layer_norm.weight	139837172265424
500	module.speech_encoder.layers.8.self_attn_layer_norm.bias	139837172265504
501	module.speech_encoder.layers.8.fc1.weight	139837172265584
502	module.speech_encoder.layers.8.fc1.bias	139837172266384
503	module.speech_encoder.layers.8.fc2.weight	139837172265344
504	module.speech_encoder.layers.8.fc2.bias	139837172265984
505	module.speech_encoder.layers.8.final_layer_norm.weight	139837172268944
506	module.speech_encoder.layers.8.final_layer_norm.bias	139837172265024
507	module.speech_encoder.layers.9.self_attn.k_proj.weight	139837172265104
508	module.speech_encoder.layers.9.self_attn.v_proj.weight	139837172265264
509	module.speech_encoder.layers.9.self_attn.v_proj.bias	139837172268864
510	module.speech_encoder.layers.9.self_attn.q_proj.weight	139837172178432
511	module.speech_encoder.layers.9.self_attn.q_proj.bias	139837172177072
512	module.speech_encoder.layers.9.self_attn.out_proj.weight	139837172285744
513	module.speech_encoder.layers.9.self_attn.out_proj.bias	139837172285664
514	module.speech_encoder.layers.9.self_attn_layer_norm.weight	139837172285504
515	module.speech_encoder.layers.9.self_attn_layer_norm.bias	139837172285584
516	module.speech_encoder.layers.9.fc1.weight	139837172285904
517	module.speech_encoder.layers.9.fc1.bias	139837172265184
518	module.speech_encoder.layers.9.fc2.weight	139837172285824
519	module.speech_encoder.layers.9.fc2.bias	139837172267984
520	module.speech_encoder.layers.9.final_layer_norm.weight	139833215987440
521	module.speech_encoder.layers.9.final_layer_norm.bias	139833215987360
522	module.speech_encoder.layers.10.self_attn.k_proj.weight	139833215987280
523	module.speech_encoder.layers.10.self_attn.v_proj.weight	139833215987120
524	module.speech_encoder.layers.10.self_attn.v_proj.bias	139833215987520
525	module.speech_encoder.layers.10.self_attn.q_proj.weight	139833215434816
526	module.speech_encoder.layers.10.self_attn.q_proj.bias	139833215434896
527	module.speech_encoder.layers.10.self_attn.out_proj.weight	139833215434976
528	module.speech_encoder.layers.10.self_attn.out_proj.bias	139833215435056
529	module.speech_encoder.layers.10.self_attn_layer_norm.weight	139833215435216
530	module.speech_encoder.layers.10.self_attn_layer_norm.bias	139833215435136
531	module.speech_encoder.layers.10.fc1.weight	139833215435296
532	module.speech_encoder.layers.10.fc1.bias	139833215987600
533	module.speech_encoder.layers.10.fc2.weight	139833215435376
534	module.speech_encoder.layers.10.fc2.bias	139833215435536
535	module.speech_encoder.layers.10.final_layer_norm.weight	139833215435776
536	module.speech_encoder.layers.10.final_layer_norm.bias	139833215435696
537	module.speech_encoder.layers.11.self_attn.k_proj.weight	139833215435616
538	module.speech_encoder.layers.11.self_attn.v_proj.weight	139833215435456
539	module.speech_encoder.layers.11.self_attn.v_proj.bias	139833215435856
540	module.speech_encoder.layers.11.self_attn.q_proj.weight	139833215436016
541	module.speech_encoder.layers.11.self_attn.q_proj.bias	139833215436096
542	module.speech_encoder.layers.11.self_attn.out_proj.weight	139833215436176
543	module.speech_encoder.layers.11.self_attn.out_proj.bias	139833215436256
544	module.speech_encoder.layers.11.self_attn_layer_norm.weight	139833215436496
545	module.speech_encoder.layers.11.self_attn_layer_norm.bias	139833215436416
546	module.speech_encoder.layers.11.fc1.weight	139833215436336
547	module.speech_encoder.layers.11.fc1.bias	139833215435936
548	module.speech_encoder.layers.11.fc2.weight	139833215436576
549	module.speech_encoder.layers.11.fc2.bias	139833215436736
550	module.speech_encoder.layers.11.final_layer_norm.weight	139833215436976
551	module.speech_encoder.layers.11.final_layer_norm.bias	139833215436896
552	module.speech_encoder.layers.12.self_attn.k_proj.weight	139833215436816
553	module.speech_encoder.layers.12.self_attn.v_proj.weight	139833215436656
554	module.speech_encoder.layers.12.self_attn.v_proj.bias	139833215437056
555	module.speech_encoder.layers.12.self_attn.q_proj.weight	139833215437216
556	module.speech_encoder.layers.12.self_attn.q_proj.bias	139833215437296
557	module.speech_encoder.layers.12.self_attn.out_proj.weight	139833215437376
558	module.speech_encoder.layers.12.self_attn.out_proj.bias	139833215437456
559	module.speech_encoder.layers.12.self_attn_layer_norm.weight	139833215437696
560	module.speech_encoder.layers.12.self_attn_layer_norm.bias	139833215437616
561	module.speech_encoder.layers.12.fc1.weight	139833215437536
562	module.speech_encoder.layers.12.fc1.bias	139833215437136
563	module.speech_encoder.layers.12.fc2.weight	139833215437776
564	module.speech_encoder.layers.12.fc2.bias	139833215437936
565	module.speech_encoder.layers.12.final_layer_norm.weight	139833215438176
566	module.speech_encoder.layers.12.final_layer_norm.bias	139833215438096
567	module.speech_encoder.layers.13.self_attn.k_proj.weight	139833215438016
568	module.speech_encoder.layers.13.self_attn.v_proj.weight	139833215437856
569	module.speech_encoder.layers.13.self_attn.v_proj.bias	139833215438256
570	module.speech_encoder.layers.13.self_attn.q_proj.weight	139833215438416
571	module.speech_encoder.layers.13.self_attn.q_proj.bias	139833215438496
572	module.speech_encoder.layers.13.self_attn.out_proj.weight	139833215438576
573	module.speech_encoder.layers.13.self_attn.out_proj.bias	139833215438656
574	module.speech_encoder.layers.13.self_attn_layer_norm.weight	139833215594560
575	module.speech_encoder.layers.13.self_attn_layer_norm.bias	139833215438336
576	module.speech_encoder.layers.13.fc1.weight	139833215438736
577	module.speech_encoder.layers.13.fc1.bias	139833215594640
578	module.speech_encoder.layers.13.fc2.weight	139833215594720
579	module.speech_encoder.layers.13.fc2.bias	139833215594880
580	module.speech_encoder.layers.13.final_layer_norm.weight	139833215595120
581	module.speech_encoder.layers.13.final_layer_norm.bias	139833215595040
582	module.speech_encoder.layers.14.self_attn.k_proj.weight	139833215594960
583	module.speech_encoder.layers.14.self_attn.v_proj.weight	139833215594800
584	module.speech_encoder.layers.14.self_attn.v_proj.bias	139833215595200
585	module.speech_encoder.layers.14.self_attn.q_proj.weight	139833215595360
586	module.speech_encoder.layers.14.self_attn.q_proj.bias	139833215595440
587	module.speech_encoder.layers.14.self_attn.out_proj.weight	139833215595520
588	module.speech_encoder.layers.14.self_attn.out_proj.bias	139833215595600
589	module.speech_encoder.layers.14.self_attn_layer_norm.weight	139833215595840
590	module.speech_encoder.layers.14.self_attn_layer_norm.bias	139833215595760
591	module.speech_encoder.layers.14.fc1.weight	139833215595680
592	module.speech_encoder.layers.14.fc1.bias	139833215595280
593	module.speech_encoder.layers.14.fc2.weight	139833215595920
594	module.speech_encoder.layers.14.fc2.bias	139833215596080
595	module.speech_encoder.layers.14.final_layer_norm.weight	139833215596320
596	module.speech_encoder.layers.14.final_layer_norm.bias	139833215596240
597	module.speech_encoder.layers.15.self_attn.k_proj.weight	139833215596160
598	module.speech_encoder.layers.15.self_attn.v_proj.weight	139833215596000
599	module.speech_encoder.layers.15.self_attn.v_proj.bias	139833215596400
600	module.speech_encoder.layers.15.self_attn.q_proj.weight	139833215596560
601	module.speech_encoder.layers.15.self_attn.q_proj.bias	139833215596640
602	module.speech_encoder.layers.15.self_attn.out_proj.weight	139833215596720
603	module.speech_encoder.layers.15.self_attn.out_proj.bias	139833215596800
604	module.speech_encoder.layers.15.self_attn_layer_norm.weight	139833215597040
605	module.speech_encoder.layers.15.self_attn_layer_norm.bias	139833215596960
606	module.speech_encoder.layers.15.fc1.weight	139833215596880
607	module.speech_encoder.layers.15.fc1.bias	139833215596480
608	module.speech_encoder.layers.15.fc2.weight	139833215597120
609	module.speech_encoder.layers.15.fc2.bias	139833215597280
610	module.speech_encoder.layers.15.final_layer_norm.weight	139833215597520
611	module.speech_encoder.layers.15.final_layer_norm.bias	139833215597440
612	module.speech_encoder.layers.16.self_attn.k_proj.weight	139833215597360
613	module.speech_encoder.layers.16.self_attn.v_proj.weight	139833215597200
614	module.speech_encoder.layers.16.self_attn.v_proj.bias	139833215597600
615	module.speech_encoder.layers.16.self_attn.q_proj.weight	139833215597760
616	module.speech_encoder.layers.16.self_attn.q_proj.bias	139833215597840
617	module.speech_encoder.layers.16.self_attn.out_proj.weight	139833215597920
618	module.speech_encoder.layers.16.self_attn.out_proj.bias	139833215598000
619	module.speech_encoder.layers.16.self_attn_layer_norm.weight	139833215598240
620	module.speech_encoder.layers.16.self_attn_layer_norm.bias	139833215598160
621	module.speech_encoder.layers.16.fc1.weight	139833215598080
622	module.speech_encoder.layers.16.fc1.bias	139833215597680
623	module.speech_encoder.layers.16.fc2.weight	139833215598320
624	module.speech_encoder.layers.16.fc2.bias	139833215598480
625	module.speech_encoder.layers.16.final_layer_norm.weight	139833215234272
626	module.speech_encoder.layers.16.final_layer_norm.bias	139833215234192
627	module.speech_encoder.layers.17.self_attn.k_proj.weight	139833215598400
628	module.speech_encoder.layers.17.self_attn.v_proj.weight	139833215234112
629	module.speech_encoder.layers.17.self_attn.v_proj.bias	139833215234352
630	module.speech_encoder.layers.17.self_attn.q_proj.weight	139833215234512
631	module.speech_encoder.layers.17.self_attn.q_proj.bias	139833215234592
632	module.speech_encoder.layers.17.self_attn.out_proj.weight	139833215234672
633	module.speech_encoder.layers.17.self_attn.out_proj.bias	139833215234752
634	module.speech_encoder.layers.17.self_attn_layer_norm.weight	139833215234992
635	module.speech_encoder.layers.17.self_attn_layer_norm.bias	139833215234912
636	module.speech_encoder.layers.17.fc1.weight	139833215234832
637	module.speech_encoder.layers.17.fc1.bias	139833215234432
638	module.speech_encoder.layers.17.fc2.weight	139833215235072
639	module.speech_encoder.layers.17.fc2.bias	139833215235232
640	module.speech_encoder.layers.17.final_layer_norm.weight	139833215235472
641	module.speech_encoder.layers.17.final_layer_norm.bias	139833215235392
642	module.speech_encoder.layers.18.self_attn.k_proj.weight	139833215235312
643	module.speech_encoder.layers.18.self_attn.v_proj.weight	139833215235152
644	module.speech_encoder.layers.18.self_attn.v_proj.bias	139833215235552
645	module.speech_encoder.layers.18.self_attn.q_proj.weight	139833215235712
646	module.speech_encoder.layers.18.self_attn.q_proj.bias	139833215235792
647	module.speech_encoder.layers.18.self_attn.out_proj.weight	139833215235872
648	module.speech_encoder.layers.18.self_attn.out_proj.bias	139833215235952
649	module.speech_encoder.layers.18.self_attn_layer_norm.weight	139833215236192
650	module.speech_encoder.layers.18.self_attn_layer_norm.bias	139833215236112
651	module.speech_encoder.layers.18.fc1.weight	139833215236032
652	module.speech_encoder.layers.18.fc1.bias	139833215235632
653	module.speech_encoder.layers.18.fc2.weight	139833215236272
654	module.speech_encoder.layers.18.fc2.bias	139833215236432
655	module.speech_encoder.layers.18.final_layer_norm.weight	139833215236672
656	module.speech_encoder.layers.18.final_layer_norm.bias	139833215236592
657	module.speech_encoder.layers.19.self_attn.k_proj.weight	139833215236512
658	module.speech_encoder.layers.19.self_attn.v_proj.weight	139833215236352
659	module.speech_encoder.layers.19.self_attn.v_proj.bias	139833215236752
660	module.speech_encoder.layers.19.self_attn.q_proj.weight	139833215236912
661	module.speech_encoder.layers.19.self_attn.q_proj.bias	139833215236992
662	module.speech_encoder.layers.19.self_attn.out_proj.weight	139833215237072
663	module.speech_encoder.layers.19.self_attn.out_proj.bias	139833215237152
664	module.speech_encoder.layers.19.self_attn_layer_norm.weight	139833215237392
665	module.speech_encoder.layers.19.self_attn_layer_norm.bias	139833215237312
666	module.speech_encoder.layers.19.fc1.weight	139833215237232
667	module.speech_encoder.layers.19.fc1.bias	139833215236832
668	module.speech_encoder.layers.19.fc2.weight	139833215237472
669	module.speech_encoder.layers.19.fc2.bias	139833215237632
670	module.speech_encoder.layers.19.final_layer_norm.weight	139833215237872
671	module.speech_encoder.layers.19.final_layer_norm.bias	139833215237792
672	module.speech_encoder.layers.20.self_attn.k_proj.weight	139833215237712
673	module.speech_encoder.layers.20.self_attn.v_proj.weight	139833215237552
674	module.speech_encoder.layers.20.self_attn.v_proj.bias	139833215237952
675	module.speech_encoder.layers.20.self_attn.q_proj.weight	139833214873664
676	module.speech_encoder.layers.20.self_attn.q_proj.bias	139833214873744
677	module.speech_encoder.layers.20.self_attn.out_proj.weight	139833214873824
678	module.speech_encoder.layers.20.self_attn.out_proj.bias	139833214873904
679	module.speech_encoder.layers.20.self_attn_layer_norm.weight	139833214874144
680	module.speech_encoder.layers.20.self_attn_layer_norm.bias	139833214874064
681	module.speech_encoder.layers.20.fc1.weight	139833214873984
682	module.speech_encoder.layers.20.fc1.bias	139833214874224
683	module.speech_encoder.layers.20.fc2.weight	139833214874304
684	module.speech_encoder.layers.20.fc2.bias	139833214874384
685	module.speech_encoder.layers.20.final_layer_norm.weight	139833214874624
686	module.speech_encoder.layers.20.final_layer_norm.bias	139833214874544
687	module.speech_encoder.layers.21.self_attn.k_proj.weight	139833214874464
688	module.speech_encoder.layers.21.self_attn.v_proj.weight	139833214874704
689	module.speech_encoder.layers.21.self_attn.v_proj.bias	139833214874784
690	module.speech_encoder.layers.21.self_attn.q_proj.weight	139833214874864
691	module.speech_encoder.layers.21.self_attn.q_proj.bias	139833214874944
692	module.speech_encoder.layers.21.self_attn.out_proj.weight	139833214875024
693	module.speech_encoder.layers.21.self_attn.out_proj.bias	139833214875104
694	module.speech_encoder.layers.21.self_attn_layer_norm.weight	139833214875344
695	module.speech_encoder.layers.21.self_attn_layer_norm.bias	139833214875264
696	module.speech_encoder.layers.21.fc1.weight	139833214875184
697	module.speech_encoder.layers.21.fc1.bias	139833214875424
698	module.speech_encoder.layers.21.fc2.weight	139833214875504
699	module.speech_encoder.layers.21.fc2.bias	139833214875584
700	module.speech_encoder.layers.21.final_layer_norm.weight	139833214875824
701	module.speech_encoder.layers.21.final_layer_norm.bias	139833214875744
702	module.speech_encoder.layers.22.self_attn.k_proj.weight	139833214875664
703	module.speech_encoder.layers.22.self_attn.v_proj.weight	139833214875904
704	module.speech_encoder.layers.22.self_attn.v_proj.bias	139833214875984
705	module.speech_encoder.layers.22.self_attn.q_proj.weight	139833214876064
706	module.speech_encoder.layers.22.self_attn.q_proj.bias	139833214876144
707	module.speech_encoder.layers.22.self_attn.out_proj.weight	139833214876224
708	module.speech_encoder.layers.22.self_attn.out_proj.bias	139833214876304
709	module.speech_encoder.layers.22.self_attn_layer_norm.weight	139833214876544
710	module.speech_encoder.layers.22.self_attn_layer_norm.bias	139833214876464
711	module.speech_encoder.layers.22.fc1.weight	139833214876384
712	module.speech_encoder.layers.22.fc1.bias	139833214876624
713	module.speech_encoder.layers.22.fc2.weight	139833214876704
714	module.speech_encoder.layers.22.fc2.bias	139833214876784
715	module.speech_encoder.layers.22.final_layer_norm.weight	139833214877024
716	module.speech_encoder.layers.22.final_layer_norm.bias	139833214876944
717	module.speech_encoder.layers.23.self_attn.k_proj.weight	139833214876864
718	module.speech_encoder.layers.23.self_attn.v_proj.weight	139833214877104
719	module.speech_encoder.layers.23.self_attn.v_proj.bias	139833214877184
720	module.speech_encoder.layers.23.self_attn.q_proj.weight	139833214877264
721	module.speech_encoder.layers.23.self_attn.q_proj.bias	139833214877344
722	module.speech_encoder.layers.23.self_attn.out_proj.weight	139833214877424
723	module.speech_encoder.layers.23.self_attn.out_proj.bias	139833214877504
724	module.speech_encoder.layers.23.self_attn_layer_norm.weight	139833215037584
725	module.speech_encoder.layers.23.self_attn_layer_norm.bias	139833215037504
726	module.speech_encoder.layers.23.fc1.weight	139833214877584
727	module.speech_encoder.layers.23.fc1.bias	139833215238032
728	module.speech_encoder.layers.23.fc2.weight	139833215037664
729	module.speech_encoder.layers.23.fc2.bias	139833215037824
730	module.speech_encoder.layers.23.final_layer_norm.weight	139833215038064
731	module.speech_encoder.layers.23.final_layer_norm.bias	139833215037984
732	module.speech_encoder.layers.24.self_attn.k_proj.weight	139833215037904
733	module.speech_encoder.layers.24.self_attn.v_proj.weight	139833215037744
734	module.speech_encoder.layers.24.self_attn.v_proj.bias	139833215038144
735	module.speech_encoder.layers.24.self_attn.q_proj.weight	139833215038304
736	module.speech_encoder.layers.24.self_attn.q_proj.bias	139833215038384
737	module.speech_encoder.layers.24.self_attn.out_proj.weight	139833215038464
738	module.speech_encoder.layers.24.self_attn.out_proj.bias	139833215038544
739	module.speech_encoder.layers.24.self_attn_layer_norm.weight	139833215038784
740	module.speech_encoder.layers.24.self_attn_layer_norm.bias	139833215038704
741	module.speech_encoder.layers.24.fc1.weight	139833215038624
742	module.speech_encoder.layers.24.fc1.bias	139833215038224
743	module.speech_encoder.layers.24.fc2.weight	139833215038864
744	module.speech_encoder.layers.24.fc2.bias	139833215039024
745	module.speech_encoder.layers.24.final_layer_norm.weight	139833215039264
746	module.speech_encoder.layers.24.final_layer_norm.bias	139833215039184
747	module.speech_encoder.layers.25.self_attn.k_proj.weight	139833215039104
748	module.speech_encoder.layers.25.self_attn.v_proj.weight	139833215038944
749	module.speech_encoder.layers.25.self_attn.v_proj.bias	139833215039344
750	module.speech_encoder.layers.25.self_attn.q_proj.weight	139833215039504
751	module.speech_encoder.layers.25.self_attn.q_proj.bias	139833215039584
752	module.speech_encoder.layers.25.self_attn.out_proj.weight	139833215039664
753	module.speech_encoder.layers.25.self_attn.out_proj.bias	139833215039744
754	module.speech_encoder.layers.25.self_attn_layer_norm.weight	139833215039984
755	module.speech_encoder.layers.25.self_attn_layer_norm.bias	139833215039904
756	module.speech_encoder.layers.25.fc1.weight	139833215039824
757	module.speech_encoder.layers.25.fc1.bias	139833215039424
758	module.speech_encoder.layers.25.fc2.weight	139833215040064
759	module.speech_encoder.layers.25.fc2.bias	139833215040224
760	module.speech_encoder.layers.25.final_layer_norm.weight	139833215040464
761	module.speech_encoder.layers.25.final_layer_norm.bias	139833215040384
762	module.speech_encoder.layers.26.self_attn.k_proj.weight	139833215040304
763	module.speech_encoder.layers.26.self_attn.v_proj.weight	139833215040144
764	module.speech_encoder.layers.26.self_attn.v_proj.bias	139833215040544
765	module.speech_encoder.layers.26.self_attn.q_proj.weight	139833215040704
766	module.speech_encoder.layers.26.self_attn.q_proj.bias	139833215040784
767	module.speech_encoder.layers.26.self_attn.out_proj.weight	139833215040864
768	module.speech_encoder.layers.26.self_attn.out_proj.bias	139833215040944
769	module.speech_encoder.layers.26.self_attn_layer_norm.weight	139833215041184
770	module.speech_encoder.layers.26.self_attn_layer_norm.bias	139833215041104
771	module.speech_encoder.layers.26.fc1.weight	139833215041024
772	module.speech_encoder.layers.26.fc1.bias	139833215040624
773	module.speech_encoder.layers.26.fc2.weight	139833215041264
774	module.speech_encoder.layers.26.fc2.bias	139833215041424
775	module.speech_encoder.layers.26.final_layer_norm.weight	139833214669024
776	module.speech_encoder.layers.26.final_layer_norm.bias	139833214668944
777	module.speech_encoder.layers.27.self_attn.k_proj.weight	139833215041344
778	module.speech_encoder.layers.27.self_attn.v_proj.weight	139833214668864
779	module.speech_encoder.layers.27.self_attn.v_proj.bias	139833214669104
780	module.speech_encoder.layers.27.self_attn.q_proj.weight	139833214669264
781	module.speech_encoder.layers.27.self_attn.q_proj.bias	139833214669344
782	module.speech_encoder.layers.27.self_attn.out_proj.weight	139833214669424
783	module.speech_encoder.layers.27.self_attn.out_proj.bias	139833214669504
784	module.speech_encoder.layers.27.self_attn_layer_norm.weight	139833214669744
785	module.speech_encoder.layers.27.self_attn_layer_norm.bias	139833214669664
786	module.speech_encoder.layers.27.fc1.weight	139833214669584
787	module.speech_encoder.layers.27.fc1.bias	139833214669184
788	module.speech_encoder.layers.27.fc2.weight	139833214669824
789	module.speech_encoder.layers.27.fc2.bias	139833214669984
790	module.speech_encoder.layers.27.final_layer_norm.weight	139833214670224
791	module.speech_encoder.layers.27.final_layer_norm.bias	139833214670144
792	module.speech_encoder.layers.28.self_attn.k_proj.weight	139833214670064
793	module.speech_encoder.layers.28.self_attn.v_proj.weight	139833214669904
794	module.speech_encoder.layers.28.self_attn.v_proj.bias	139833214670304
795	module.speech_encoder.layers.28.self_attn.q_proj.weight	139833214670464
796	module.speech_encoder.layers.28.self_attn.q_proj.bias	139833214670544
797	module.speech_encoder.layers.28.self_attn.out_proj.weight	139833214670624
798	module.speech_encoder.layers.28.self_attn.out_proj.bias	139833214670704
799	module.speech_encoder.layers.28.self_attn_layer_norm.weight	139833214670944
800	module.speech_encoder.layers.28.self_attn_layer_norm.bias	139833214670864
801	module.speech_encoder.layers.28.fc1.weight	139833214670784
802	module.speech_encoder.layers.28.fc1.bias	139833214670384
803	module.speech_encoder.layers.28.fc2.weight	139833214671024
804	module.speech_encoder.layers.28.fc2.bias	139833214671184
805	module.speech_encoder.layers.28.final_layer_norm.weight	139833214671424
806	module.speech_encoder.layers.28.final_layer_norm.bias	139833214671344
807	module.speech_encoder.layers.29.self_attn.k_proj.weight	139833214671264
808	module.speech_encoder.layers.29.self_attn.v_proj.weight	139833214671104
809	module.speech_encoder.layers.29.self_attn.v_proj.bias	139833214671504
810	module.speech_encoder.layers.29.self_attn.q_proj.weight	139833214671664
811	module.speech_encoder.layers.29.self_attn.q_proj.bias	139833214671744
812	module.speech_encoder.layers.29.self_attn.out_proj.weight	139833214671824
813	module.speech_encoder.layers.29.self_attn.out_proj.bias	139833214671904
814	module.speech_encoder.layers.29.self_attn_layer_norm.weight	139833214672144
815	module.speech_encoder.layers.29.self_attn_layer_norm.bias	139833214672064
816	module.speech_encoder.layers.29.fc1.weight	139833214671984
817	module.speech_encoder.layers.29.fc1.bias	139833214671584
818	module.speech_encoder.layers.29.fc2.weight	139833214672224
819	module.speech_encoder.layers.29.fc2.bias	139833214672384
820	module.speech_encoder.layers.29.final_layer_norm.weight	139833214672624
821	module.speech_encoder.layers.29.final_layer_norm.bias	139833214672544
822	module.speech_encoder.layers.30.self_attn.k_proj.weight	139833214672464
823	module.speech_encoder.layers.30.self_attn.v_proj.weight	139833214672304
824	module.speech_encoder.layers.30.self_attn.v_proj.bias	139833214672704
825	module.speech_encoder.layers.30.self_attn.q_proj.weight	139833214836800
826	module.speech_encoder.layers.30.self_attn.q_proj.bias	139833214836880
827	module.speech_encoder.layers.30.self_attn.out_proj.weight	139833214836960
828	module.speech_encoder.layers.30.self_attn.out_proj.bias	139833214837040
829	module.speech_encoder.layers.30.self_attn_layer_norm.weight	139833214837280
830	module.speech_encoder.layers.30.self_attn_layer_norm.bias	139833214837200
831	module.speech_encoder.layers.30.fc1.weight	139833214837120
832	module.speech_encoder.layers.30.fc1.bias	139833214837360
833	module.speech_encoder.layers.30.fc2.weight	139833214837440
834	module.speech_encoder.layers.30.fc2.bias	139833214837520
835	module.speech_encoder.layers.30.final_layer_norm.weight	139833214837760
836	module.speech_encoder.layers.30.final_layer_norm.bias	139833214837680
837	module.speech_encoder.layers.31.self_attn.k_proj.weight	139833214837600
838	module.speech_encoder.layers.31.self_attn.v_proj.weight	139833214837840
839	module.speech_encoder.layers.31.self_attn.v_proj.bias	139833214837920
840	module.speech_encoder.layers.31.self_attn.q_proj.weight	139833214838000
841	module.speech_encoder.layers.31.self_attn.q_proj.bias	139833214838080
842	module.speech_encoder.layers.31.self_attn.out_proj.weight	139833214838160
843	module.speech_encoder.layers.31.self_attn.out_proj.bias	139833214838240
844	module.speech_encoder.layers.31.self_attn_layer_norm.weight	139833214838480
845	module.speech_encoder.layers.31.self_attn_layer_norm.bias	139833214838400
846	module.speech_encoder.layers.31.fc1.weight	139833214838320
847	module.speech_encoder.layers.31.fc1.bias	139833214838560
848	module.speech_encoder.layers.31.fc2.weight	139833214838640
849	module.speech_encoder.layers.31.fc2.bias	139833214838720
850	module.speech_encoder.layers.31.final_layer_norm.weight	139833214838960
851	module.speech_encoder.layers.31.final_layer_norm.bias	139833214838880
852	module.speech_encoder.layer_norm.weight	139837172281408
853	module.speech_encoder.layer_norm.bias	139837172281488
854	module.ln_speech.weight	139833214115648
855	module.ln_speech.bias	139833214114848
856	module.beats.post_extract_proj.weight	139833214115568
857	module.beats.post_extract_proj.bias	139833214115728
858	module.beats.patch_embedding.weight	139833214113728
859	module.beats.encoder.pos_conv.0.bias	139833216358976
860	module.beats.encoder.pos_conv.0.weight_g	139833214115408
861	module.beats.encoder.pos_conv.0.weight_v	139833216358576
862	module.beats.encoder.layers.0.self_attn.grep_a	139833216354400
863	module.beats.encoder.layers.0.self_attn.relative_attention_bias.weight	139833216355280
864	module.beats.encoder.layers.0.self_attn.k_proj.weight	139833216355520
865	module.beats.encoder.layers.0.self_attn.k_proj.bias	139833216355600
866	module.beats.encoder.layers.0.self_attn.v_proj.weight	139833216355360
867	module.beats.encoder.layers.0.self_attn.v_proj.bias	139833216355040
868	module.beats.encoder.layers.0.self_attn.q_proj.weight	139833216355120
869	module.beats.encoder.layers.0.self_attn.q_proj.bias	139833216354800
870	module.beats.encoder.layers.0.self_attn.out_proj.weight	139833216354880
871	module.beats.encoder.layers.0.self_attn.out_proj.bias	139833216354560
872	module.beats.encoder.layers.0.self_attn.grep_linear.weight	139833216354640
873	module.beats.encoder.layers.0.self_attn.grep_linear.bias	139833216354320
874	module.beats.encoder.layers.0.self_attn_layer_norm.weight	139833216354080
875	module.beats.encoder.layers.0.self_attn_layer_norm.bias	139833216354160
876	module.beats.encoder.layers.0.fc1.weight	139833216353840
877	module.beats.encoder.layers.0.fc1.bias	139833216353920
878	module.beats.encoder.layers.0.fc2.weight	139833216353600
879	module.beats.encoder.layers.0.fc2.bias	139833216353680
880	module.beats.encoder.layers.0.final_layer_norm.weight	139833216353360
881	module.beats.encoder.layers.0.final_layer_norm.bias	139833216353440
882	module.beats.encoder.layers.1.self_attn.grep_a	139833216351904
883	module.beats.encoder.layers.1.self_attn.k_proj.weight	139833216353200
884	module.beats.encoder.layers.1.self_attn.k_proj.bias	139833216352880
885	module.beats.encoder.layers.1.self_attn.v_proj.weight	139833216352960
886	module.beats.encoder.layers.1.self_attn.v_proj.bias	139833216352640
887	module.beats.encoder.layers.1.self_attn.q_proj.weight	139833216352720
888	module.beats.encoder.layers.1.self_attn.q_proj.bias	139833216352400
889	module.beats.encoder.layers.1.self_attn.out_proj.weight	139833216352480
890	module.beats.encoder.layers.1.self_attn.out_proj.bias	139833216352064
891	module.beats.encoder.layers.1.self_attn.grep_linear.weight	139833216352144
892	module.beats.encoder.layers.1.self_attn.grep_linear.bias	139833216351824
893	module.beats.encoder.layers.1.self_attn_layer_norm.weight	139833216351584
894	module.beats.encoder.layers.1.self_attn_layer_norm.bias	139833216351664
895	module.beats.encoder.layers.1.fc1.weight	139833216351344
896	module.beats.encoder.layers.1.fc1.bias	139833216351424
897	module.beats.encoder.layers.1.fc2.weight	139833216351104
898	module.beats.encoder.layers.1.fc2.bias	139833216351184
899	module.beats.encoder.layers.1.final_layer_norm.weight	139833216350864
900	module.beats.encoder.layers.1.final_layer_norm.bias	139833216350944
901	module.beats.encoder.layers.2.self_attn.grep_a	139833216349504
902	module.beats.encoder.layers.2.self_attn.k_proj.weight	139833216350704
903	module.beats.encoder.layers.2.self_attn.k_proj.bias	139833216350384
904	module.beats.encoder.layers.2.self_attn.v_proj.weight	139833216350464
905	module.beats.encoder.layers.2.self_attn.v_proj.bias	139833216350144
906	module.beats.encoder.layers.2.self_attn.q_proj.weight	139833216350224
907	module.beats.encoder.layers.2.self_attn.q_proj.bias	139833216349904
908	module.beats.encoder.layers.2.self_attn.out_proj.weight	139833216349984
909	module.beats.encoder.layers.2.self_attn.out_proj.bias	139833216349664
910	module.beats.encoder.layers.2.self_attn.grep_linear.weight	139833216349744
911	module.beats.encoder.layers.2.self_attn.grep_linear.bias	139833216349424
912	module.beats.encoder.layers.2.self_attn_layer_norm.weight	139833216349184
913	module.beats.encoder.layers.2.self_attn_layer_norm.bias	139833216349264
914	module.beats.encoder.layers.2.fc1.weight	139833216348944
915	module.beats.encoder.layers.2.fc1.bias	139833216349024
916	module.beats.encoder.layers.2.fc2.weight	139833216348704
917	module.beats.encoder.layers.2.fc2.bias	139833216348784
918	module.beats.encoder.layers.2.final_layer_norm.weight	139833216348464
919	module.beats.encoder.layers.2.final_layer_norm.bias	139833216348544
920	module.beats.encoder.layers.3.self_attn.grep_a	139833216347008
921	module.beats.encoder.layers.3.self_attn.k_proj.weight	139833216348304
922	module.beats.encoder.layers.3.self_attn.k_proj.bias	139833216347888
923	module.beats.encoder.layers.3.self_attn.v_proj.weight	139833216347968
924	module.beats.encoder.layers.3.self_attn.v_proj.bias	139833216347648
925	module.beats.encoder.layers.3.self_attn.q_proj.weight	139833216347728
926	module.beats.encoder.layers.3.self_attn.q_proj.bias	139833216347408
927	module.beats.encoder.layers.3.self_attn.out_proj.weight	139833216347488
928	module.beats.encoder.layers.3.self_attn.out_proj.bias	139833216347168
929	module.beats.encoder.layers.3.self_attn.grep_linear.weight	139833216347248
930	module.beats.encoder.layers.3.self_attn.grep_linear.bias	139833216346928
931	module.beats.encoder.layers.3.self_attn_layer_norm.weight	139833216346688
932	module.beats.encoder.layers.3.self_attn_layer_norm.bias	139833216346768
933	module.beats.encoder.layers.3.fc1.weight	139833216346448
934	module.beats.encoder.layers.3.fc1.bias	139833216346528
935	module.beats.encoder.layers.3.fc2.weight	139833216346208
936	module.beats.encoder.layers.3.fc2.bias	139833216346288
937	module.beats.encoder.layers.3.final_layer_norm.weight	139833216345968
938	module.beats.encoder.layers.3.final_layer_norm.bias	139833216346048
939	module.beats.encoder.layers.4.self_attn.grep_a	139833216344608
940	module.beats.encoder.layers.4.self_attn.k_proj.weight	139833216345808
941	module.beats.encoder.layers.4.self_attn.k_proj.bias	139833216345488
942	module.beats.encoder.layers.4.self_attn.v_proj.weight	139833216345568
943	module.beats.encoder.layers.4.self_attn.v_proj.bias	139833216345248
944	module.beats.encoder.layers.4.self_attn.q_proj.weight	139833216345328
945	module.beats.encoder.layers.4.self_attn.q_proj.bias	139833216345008
946	module.beats.encoder.layers.4.self_attn.out_proj.weight	139833216345088
947	module.beats.encoder.layers.4.self_attn.out_proj.bias	139833216344768
948	module.beats.encoder.layers.4.self_attn.grep_linear.weight	139833216344848
949	module.beats.encoder.layers.4.self_attn.grep_linear.bias	139833216344528
950	module.beats.encoder.layers.4.self_attn_layer_norm.weight	139833216344288
951	module.beats.encoder.layers.4.self_attn_layer_norm.bias	139833216344368
952	module.beats.encoder.layers.4.fc1.weight	139833216344128
953	module.beats.encoder.layers.4.fc1.bias	139833216339856
954	module.beats.encoder.layers.4.fc2.weight	139833216339616
955	module.beats.encoder.layers.4.fc2.bias	139833216339696
956	module.beats.encoder.layers.4.final_layer_norm.weight	139833216339376
957	module.beats.encoder.layers.4.final_layer_norm.bias	139833216339456
958	module.beats.encoder.layers.5.self_attn.grep_a	139833216338016
959	module.beats.encoder.layers.5.self_attn.k_proj.weight	139833216339216
960	module.beats.encoder.layers.5.self_attn.k_proj.bias	139833216338896
961	module.beats.encoder.layers.5.self_attn.v_proj.weight	139833216338976
962	module.beats.encoder.layers.5.self_attn.v_proj.bias	139833216338656
963	module.beats.encoder.layers.5.self_attn.q_proj.weight	139833216338736
964	module.beats.encoder.layers.5.self_attn.q_proj.bias	139833216338416
965	module.beats.encoder.layers.5.self_attn.out_proj.weight	139833216338496
966	module.beats.encoder.layers.5.self_attn.out_proj.bias	139833216338176
967	module.beats.encoder.layers.5.self_attn.grep_linear.weight	139833216338256
968	module.beats.encoder.layers.5.self_attn.grep_linear.bias	139833216337936
969	module.beats.encoder.layers.5.self_attn_layer_norm.weight	139833216337696
970	module.beats.encoder.layers.5.self_attn_layer_norm.bias	139833216337776
971	module.beats.encoder.layers.5.fc1.weight	139833216337456
972	module.beats.encoder.layers.5.fc1.bias	139833216337536
973	module.beats.encoder.layers.5.fc2.weight	139833216337216
974	module.beats.encoder.layers.5.fc2.bias	139833216337296
975	module.beats.encoder.layers.5.final_layer_norm.weight	139833216336976
976	module.beats.encoder.layers.5.final_layer_norm.bias	139833216337056
977	module.beats.encoder.layers.6.self_attn.grep_a	139833217149984
978	module.beats.encoder.layers.6.self_attn.k_proj.weight	139833216336816
979	module.beats.encoder.layers.6.self_attn.k_proj.bias	139833216336496
980	module.beats.encoder.layers.6.self_attn.v_proj.weight	139833216336576
981	module.beats.encoder.layers.6.self_attn.v_proj.bias	139833216336256
982	module.beats.encoder.layers.6.self_attn.q_proj.weight	139833216336336
983	module.beats.encoder.layers.6.self_attn.q_proj.bias	139833216336016
984	module.beats.encoder.layers.6.self_attn.out_proj.weight	139833216336096
985	module.beats.encoder.layers.6.self_attn.out_proj.bias	139833217149264
986	module.beats.encoder.layers.6.self_attn.grep_linear.weight	139833217149504
987	module.beats.encoder.layers.6.self_attn.grep_linear.bias	139833217149024
988	module.beats.encoder.layers.6.self_attn_layer_norm.weight	139833217150224
989	module.beats.encoder.layers.6.self_attn_layer_norm.bias	139833217150464
990	module.beats.encoder.layers.6.fc1.weight	139833217150704
991	module.beats.encoder.layers.6.fc1.bias	139833217149744
992	module.beats.encoder.layers.6.fc2.weight	139833217150784
993	module.beats.encoder.layers.6.fc2.bias	139833217150864
994	module.beats.encoder.layers.6.final_layer_norm.weight	139833217150544
995	module.beats.encoder.layers.6.final_layer_norm.bias	139833217150624
996	module.beats.encoder.layers.7.self_attn.grep_a	139833217149184
997	module.beats.encoder.layers.7.self_attn.k_proj.weight	139833217150384
998	module.beats.encoder.layers.7.self_attn.k_proj.bias	139833217150064
999	module.beats.encoder.layers.7.self_attn.v_proj.weight	139833217150144
1000	module.beats.encoder.layers.7.self_attn.v_proj.bias	139833217149824
1001	module.beats.encoder.layers.7.self_attn.q_proj.weight	139833217149904
1002	module.beats.encoder.layers.7.self_attn.q_proj.bias	139833217149584
1003	module.beats.encoder.layers.7.self_attn.out_proj.weight	139833217149664
1004	module.beats.encoder.layers.7.self_attn.out_proj.bias	139833217149344
1005	module.beats.encoder.layers.7.self_attn.grep_linear.weight	139833217149424
1006	module.beats.encoder.layers.7.self_attn.grep_linear.bias	139833217149104
1007	module.beats.encoder.layers.7.self_attn_layer_norm.weight	139833217148944
1008	module.beats.encoder.layers.7.self_attn_layer_norm.bias	139833218124992
1009	module.beats.encoder.layers.7.fc1.weight	139833218509936
1010	module.beats.encoder.layers.7.fc1.bias	139833218509456
1011	module.beats.encoder.layers.7.fc2.weight	139833218506816
1012	module.beats.encoder.layers.7.fc2.bias	139833218507856
1013	module.beats.encoder.layers.7.final_layer_norm.weight	139833218510176
1014	module.beats.encoder.layers.7.final_layer_norm.bias	139833218510576
1015	module.beats.encoder.layers.8.self_attn.grep_a	139833472091296
1016	module.beats.encoder.layers.8.self_attn.k_proj.weight	139833218510496
1017	module.beats.encoder.layers.8.self_attn.k_proj.bias	139833218508336
1018	module.beats.encoder.layers.8.self_attn.v_proj.weight	139833218961136
1019	module.beats.encoder.layers.8.self_attn.v_proj.bias	139833218960736
1020	module.beats.encoder.layers.8.self_attn.q_proj.weight	139833218961296
1021	module.beats.encoder.layers.8.self_attn.q_proj.bias	139833472504032
1022	module.beats.encoder.layers.8.self_attn.out_proj.weight	139833472090896
1023	module.beats.encoder.layers.8.self_attn.out_proj.bias	139833472091056
1024	module.beats.encoder.layers.8.self_attn.grep_linear.weight	139833472092496
1025	module.beats.encoder.layers.8.self_attn.grep_linear.bias	139833472091696
1026	module.beats.encoder.layers.8.self_attn_layer_norm.weight	139833472091616
1027	module.beats.encoder.layers.8.self_attn_layer_norm.bias	139833472092256
1028	module.beats.encoder.layers.8.fc1.weight	139833472091456
1029	module.beats.encoder.layers.8.fc1.bias	139833472090176
1030	module.beats.encoder.layers.8.fc2.weight	139833472090736
1031	module.beats.encoder.layers.8.fc2.bias	139833472091536
1032	module.beats.encoder.layers.8.final_layer_norm.weight	139833472090976
1033	module.beats.encoder.layers.8.final_layer_norm.bias	139833472092576
1034	module.beats.encoder.layers.9.self_attn.grep_a	139833472091136
1035	module.beats.encoder.layers.9.self_attn.k_proj.weight	139833472092336
1036	module.beats.encoder.layers.9.self_attn.k_proj.bias	139833472090496
1037	module.beats.encoder.layers.9.self_attn.v_proj.weight	139833472090656
1038	module.beats.encoder.layers.9.self_attn.v_proj.bias	139833472092416
1039	module.beats.encoder.layers.9.self_attn.q_proj.weight	139833472091216
1040	module.beats.encoder.layers.9.self_attn.q_proj.bias	139833472092176
1041	module.beats.encoder.layers.9.self_attn.out_proj.weight	139833472090816
1042	module.beats.encoder.layers.9.self_attn.out_proj.bias	139833472091376
1043	module.beats.encoder.layers.9.self_attn.grep_linear.weight	139833472090576
1044	module.beats.encoder.layers.9.self_attn.grep_linear.bias	139833472090336
1045	module.beats.encoder.layers.9.self_attn_layer_norm.weight	139833472090416
1046	module.beats.encoder.layers.9.self_attn_layer_norm.bias	139833472090256
1047	module.beats.encoder.layers.9.fc1.weight	139833472080848
1048	module.beats.encoder.layers.9.fc1.bias	139833472081248
1049	module.beats.encoder.layers.9.fc2.weight	139833472079808
1050	module.beats.encoder.layers.9.fc2.bias	139833472080288
1051	module.beats.encoder.layers.9.final_layer_norm.weight	139833472078608
1052	module.beats.encoder.layers.9.final_layer_norm.bias	139833472078528
1053	module.beats.encoder.layers.10.self_attn.grep_a	139833472080528
1054	module.beats.encoder.layers.10.self_attn.k_proj.weight	139833472078688
1055	module.beats.encoder.layers.10.self_attn.k_proj.bias	139833472081168
1056	module.beats.encoder.layers.10.self_attn.v_proj.weight	139833472078768
1057	module.beats.encoder.layers.10.self_attn.v_proj.bias	139833472079408
1058	module.beats.encoder.layers.10.self_attn.q_proj.weight	139833472078448
1059	module.beats.encoder.layers.10.self_attn.q_proj.bias	139833472080928
1060	module.beats.encoder.layers.10.self_attn.out_proj.weight	139833472080768
1061	module.beats.encoder.layers.10.self_attn.out_proj.bias	139833472081088
1062	module.beats.encoder.layers.10.self_attn.grep_linear.weight	139833472080688
1063	module.beats.encoder.layers.10.self_attn.grep_linear.bias	139833472079728
1064	module.beats.encoder.layers.10.self_attn_layer_norm.weight	139833472080368
1065	module.beats.encoder.layers.10.self_attn_layer_norm.bias	139833472080128
1066	module.beats.encoder.layers.10.fc1.weight	139833472080048
1067	module.beats.encoder.layers.10.fc1.bias	139833472080608
1068	module.beats.encoder.layers.10.fc2.weight	139833472079328
1069	module.beats.encoder.layers.10.fc2.bias	139833472079088
1070	module.beats.encoder.layers.10.final_layer_norm.weight	139833472079008
1071	module.beats.encoder.layers.10.final_layer_norm.bias	139833472079488
1072	module.beats.encoder.layers.11.self_attn.grep_a	139833472079248
1073	module.beats.encoder.layers.11.self_attn.k_proj.weight	139833472079168
1074	module.beats.encoder.layers.11.self_attn.k_proj.bias	139833472081728
1075	module.beats.encoder.layers.11.self_attn.v_proj.weight	139833472079968
1076	module.beats.encoder.layers.11.self_attn.v_proj.bias	139833472078928
1077	module.beats.encoder.layers.11.self_attn.q_proj.weight	139833472078208
1078	module.beats.encoder.layers.11.self_attn.q_proj.bias	139833472080448
1079	module.beats.encoder.layers.11.self_attn.out_proj.weight	139833472080208
1080	module.beats.encoder.layers.11.self_attn.out_proj.bias	139833472081328
1081	module.beats.encoder.layers.11.self_attn.grep_linear.weight	139833472081008
1082	module.beats.encoder.layers.11.self_attn.grep_linear.bias	139833472079648
1083	module.beats.encoder.layers.11.self_attn_layer_norm.weight	139833472078848
1084	module.beats.encoder.layers.11.self_attn_layer_norm.bias	139833472079888
1085	module.beats.encoder.layers.11.fc1.weight	139833472078288
1086	module.beats.encoder.layers.11.fc1.bias	139833472079568
1087	module.beats.encoder.layers.11.fc2.weight	139833472078128
1088	module.beats.encoder.layers.11.fc2.bias	139833472078368
1089	module.beats.encoder.layers.11.final_layer_norm.weight	139833472077888
1090	module.beats.encoder.layers.11.final_layer_norm.bias	139833472068800
1091	module.beats.encoder.layer_norm.weight	139833472078048
1092	module.beats.encoder.layer_norm.bias	139833216359296
1093	module.beats.layer_norm.weight	139833218508016
1094	module.beats.layer_norm.bias	139833217150304
1095	module.beats.predictor.weight	139833216336736
1096	module.beats.predictor.bias	139833216339136
1097	module.ln_audio.weight	139833218960896
1098	module.ln_audio.bias	139833472461056
1099	module.speech_Qformer.bert.embeddings.LayerNorm.weight	139833472069360
1100	module.speech_Qformer.bert.embeddings.LayerNorm.bias	139833472065840
1101	module.speech_Qformer.bert.encoder.layer.0.attention.self.query.weight	139833472068320
1102	module.speech_Qformer.bert.encoder.layer.0.attention.self.query.bias	139833472069440
1103	module.speech_Qformer.bert.encoder.layer.0.attention.self.key.weight	139833472066560
1104	module.speech_Qformer.bert.encoder.layer.0.attention.self.key.bias	139833472067440
1105	module.speech_Qformer.bert.encoder.layer.0.attention.self.value.weight	139833472068000
1106	module.speech_Qformer.bert.encoder.layer.0.attention.self.value.bias	139833472067040
1107	module.speech_Qformer.bert.encoder.layer.0.attention.output.dense.weight	139833216358816
1108	module.speech_Qformer.bert.encoder.layer.0.attention.output.dense.bias	139833472069200
1109	module.speech_Qformer.bert.encoder.layer.0.attention.output.LayerNorm.weight	139833472069520
1110	module.speech_Qformer.bert.encoder.layer.0.attention.output.LayerNorm.bias	139833472066720
1111	module.speech_Qformer.bert.encoder.layer.0.crossattention.self.query.weight	139833472066640
1112	module.speech_Qformer.bert.encoder.layer.0.crossattention.self.query.bias	139833472067200
1113	module.speech_Qformer.bert.encoder.layer.0.crossattention.self.key.weight	139833472066880
1114	module.speech_Qformer.bert.encoder.layer.0.crossattention.self.key.bias	139833472065920
1115	module.speech_Qformer.bert.encoder.layer.0.crossattention.self.value.weight	139833472066160
1116	module.speech_Qformer.bert.encoder.layer.0.crossattention.self.value.bias	139833472065760
1117	module.speech_Qformer.bert.encoder.layer.0.crossattention.output.dense.weight	139833472558160
1118	module.speech_Qformer.bert.encoder.layer.0.crossattention.output.dense.bias	139833472558480
1119	module.speech_Qformer.bert.encoder.layer.0.crossattention.output.LayerNorm.weight	139833472559120
1120	module.speech_Qformer.bert.encoder.layer.0.crossattention.output.LayerNorm.bias	139833472557120
1121	module.speech_Qformer.bert.encoder.layer.0.intermediate_query.dense.weight	139833472558000
1122	module.speech_Qformer.bert.encoder.layer.0.intermediate_query.dense.bias	139833472559040
1123	module.speech_Qformer.bert.encoder.layer.0.output_query.dense.weight	139833472558880
1124	module.speech_Qformer.bert.encoder.layer.0.output_query.dense.bias	139833472559200
1125	module.speech_Qformer.bert.encoder.layer.0.output_query.LayerNorm.weight	139833472559360
1126	module.speech_Qformer.bert.encoder.layer.0.output_query.LayerNorm.bias	139833472558320
1127	module.speech_Qformer.bert.encoder.layer.1.attention.self.query.weight	139833472558400
1128	module.speech_Qformer.bert.encoder.layer.1.attention.self.query.bias	139833472557760
1129	module.speech_Qformer.bert.encoder.layer.1.attention.self.key.weight	139833472558720
1130	module.speech_Qformer.bert.encoder.layer.1.attention.self.key.bias	139833472559280
1131	module.speech_Qformer.bert.encoder.layer.1.attention.self.value.weight	139833472558080
1132	module.speech_Qformer.bert.encoder.layer.1.attention.self.value.bias	139833472558960
1133	module.speech_Qformer.bert.encoder.layer.1.attention.output.dense.weight	139833472557920
1134	module.speech_Qformer.bert.encoder.layer.1.attention.output.dense.bias	139833472558640
1135	module.speech_Qformer.bert.encoder.layer.1.attention.output.LayerNorm.weight	139833472557440
1136	module.speech_Qformer.bert.encoder.layer.1.attention.output.LayerNorm.bias	139833472558240
1137	module.speech_Qformer.bert.encoder.layer.1.crossattention.self.query.weight	139833472557360
1138	module.speech_Qformer.bert.encoder.layer.1.crossattention.self.query.bias	139833472557520
1139	module.speech_Qformer.bert.encoder.layer.1.crossattention.self.key.weight	139833472441696
1140	module.speech_Qformer.bert.encoder.layer.1.crossattention.self.key.bias	139833472442016
1141	module.speech_Qformer.bert.encoder.layer.1.crossattention.self.value.weight	139833472439776
1142	module.speech_Qformer.bert.encoder.layer.1.crossattention.self.value.bias	139833472441296
1143	module.speech_Qformer.bert.encoder.layer.1.crossattention.output.dense.weight	139840443630992
1144	module.speech_Qformer.bert.encoder.layer.1.crossattention.output.dense.bias	139840443629712
1145	module.speech_Qformer.bert.encoder.layer.1.crossattention.output.LayerNorm.weight	139840443629952
1146	module.speech_Qformer.bert.encoder.layer.1.crossattention.output.LayerNorm.bias	139840443630192
1147	module.speech_Qformer.bert.encoder.layer.1.intermediate_query.dense.weight	139840443630752
1148	module.speech_Qformer.bert.encoder.layer.1.intermediate_query.dense.bias	139840443630032
1149	module.speech_Qformer.bert.encoder.layer.1.output_query.dense.weight	139840443630592
1150	module.speech_Qformer.bert.encoder.layer.1.output_query.dense.bias	139840443630832
1151	module.speech_Qformer.bert.encoder.layer.1.output_query.LayerNorm.weight	139840443630352
1152	module.speech_Qformer.bert.encoder.layer.1.output_query.LayerNorm.bias	139840443630912
1153	module.speech_llama_proj.weight	139833472066800
1154	module.speech_llama_proj.bias	139840443630112
